{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the rectrangle-shaped fuzzy number set definition, we apply the ASHLO algorithm to optimize the interval of universe discourse and offsets at two ends dynamically as time moves forward. The fitness function is to minimize the final RMSE of test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rectangle_fuzzy import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def binary_to_decimal(binary, di=0):\n",
    "    decimal = 0\n",
    "    for i in range(len(binary)):\n",
    "        if i<len(binary)-di+1:\n",
    "            power = len(binary)-(i+1)-di\n",
    "            decimal += int(binary[i]) * (2**power)\n",
    "        else:\n",
    "            power = len(binary)-(i+1)-di\n",
    "            decimal += int(binary[i]) * (2**(-power))\n",
    "    return decimal\n",
    "\n",
    "def universe_partition_adjusted(data, n=10, d1=10, d2=10):\n",
    "    x_max, x_min = data.max(axis=0), data.min(axis=0)   \n",
    "    delta = x_max - x_min\n",
    "    std_val = data.std(axis=0)\n",
    "    len_val = np.round(std_val / (n+5)) # partition interval\n",
    "    u_max, u_min = int(x_max+(d2+1)*delta/100), int(x_min-(d1+1)*delta/100) # bound of universe discourse\n",
    "    u_b = np.arange(u_min, u_max, step=float(len_val)) # cutting points\n",
    "    u_discourse = u_b\n",
    "    return u_discourse\n",
    "\n",
    "def compute_fitness(data, n, d1, d2, option='Price'):\n",
    "    first_date = data['Date'][0] - pd.DateOffset(days=1)\n",
    "    train_data = data.iloc[:-5]\n",
    "    valid_data = data.iloc[-6:]\n",
    "    fit_prices = list()\n",
    "    u_discourse = universe_partition_adjusted(train_data[option], n, d1, d2)\n",
    "    A_list = set_fuzzy_numbers(u_discourse)\n",
    "    train_data_membership_series = membership_assignment(train_data[option], fuzzy_numbers=u_discourse)\n",
    "    transition_FLR = FLR(train_data_membership_series)\n",
    "    train_data_days = train_data['Date'].apply(lambda x: x-first_date).dt.days.tolist()\n",
    "    jump_weights = FLR_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    transition_weights = FRG_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    for price in valid_data.iloc[:-1][option]:\n",
    "        index = get_membership(price, u_discourse)\n",
    "        next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "        fit_prices.append(next_price)\n",
    "    return np.sqrt(mean_squared_error(valid_data.iloc[1:][option], fit_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "start_time = time()\n",
    "datafile = '../data/IBEX35.csv'\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%m/%d/%y')\n",
    "df = pd.read_csv(datafile, header=0, parse_dates=['Date'], date_parser=dateparse)\n",
    "\n",
    "split_date = pd.datetime.strptime('2014-12-31', '%Y-%m-%d')\n",
    "train_data = df[df['Date'] < split_date]\n",
    "test_data = df[df['Date'] >= split_date]\n",
    "first_date = train_data['Date'][0] - pd.DateOffset(days=1)\n",
    "\n",
    "option = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the parameters of ASHLO algorithm\n",
    "d1_digits = 4\n",
    "n_digits = 6\n",
    "d2_digits = 4\n",
    "population = 20\n",
    "iter_max = 100\n",
    "pr = 0.1\n",
    "pi = 0.9\n",
    "\n",
    "dim_IKD = d1_digits+n_digits+d2_digits\n",
    "RMSE_list = list() # training data RMSE as fitness function value\n",
    "IKD = np.zeros((population, dim_IKD), dtype=int) # individual learning \n",
    "SKD = np.array([]) # social network learning\n",
    "RMSE_min = 0 # best fitness value\n",
    "\n",
    "for i in range(population):\n",
    "    for j in range(dim_IKD):\n",
    "        r = np.random.rand()\n",
    "        if r>0.5:\n",
    "            IKD[i, j] = 0\n",
    "        else:\n",
    "            IKD[i, j] = 1\n",
    "    d1 = binary_to_decimal(IKD[i, 0:d1_digits])\n",
    "    d2 = binary_to_decimal(IKD[i, (d1_digits+n_digits): dim_IKD])\n",
    "    n_par = binary_to_decimal(IKD[i, d1_digits:(d1_digits+n_digits)])\n",
    "    rmse = compute_fitness(train_data, n_par, d1, d2)\n",
    "    RMSE_list.append(rmse)\n",
    "RMSE_min = np.min(RMSE_list)\n",
    "SKD = np.array(IKD[np.argmin(RMSE_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iter_count in range(iter_max):\n",
    "    temp_IKD = np.zeros((population, dim_IKD))\n",
    "    temp_rmse_list = list()\n",
    "    # learning process\n",
    "    for i in range(population):\n",
    "        for j in range(dim_IKD):\n",
    "            p = np.random.rand()\n",
    "            if p < pi:\n",
    "                r = np.random.rand()\n",
    "                if r > 0.5:\n",
    "                    temp_IKD[i, j] = 1\n",
    "            elif pi <= p <= pr:\n",
    "                temp_IKD[i,j] = IKD[i, j]\n",
    "            else:\n",
    "                temp_IKD[i,j] = SKD[j]\n",
    "    # update fitness of newly learned knowledge \n",
    "    for i in range(population):\n",
    "        d1 = binary_to_decimal(temp_IKD[i, 0:d1_digits])\n",
    "        d2 = binary_to_decimal(temp_IKD[i, (d1_digits+n_digits): dim_IKD])\n",
    "        n_par = binary_to_decimal(temp_IKD[i, d1_digits:(d1_digits+n_digits)])\n",
    "        rmse = compute_fitness(train_data, n_par, d1, d2)\n",
    "        temp_rmse_list.append(rmse)\n",
    "        \n",
    "    # update knowledge base if necessary\n",
    "    RMSE_max = np.max(RMSE_list) # worst individual fitness\n",
    "    RMSE_max_index = np.argmax(RMSE_list)\n",
    "    for i in range(population):\n",
    "        if temp_rmse_list[i] < RMSE_max:\n",
    "            IKD[RMSE_max_index] = temp_IKD[i]\n",
    "            RMSE_list[RMSE_max_index] = temp_rmse_list[i]\n",
    "            RMSE_max = np.max(RMSE_list)\n",
    "            RMSE_max_index = np.argmax(RMSE_list)\n",
    "    temp_rmse_min = np.min(RMSE_list) # best individual fitness\n",
    "    if RMSE_min > temp_rmse_min:\n",
    "        SKD = np.array(IKD[np.argmin(RMSE_list)])\n",
    "        RMSE_min = temp_rmse_min\n",
    "#     print RMSE_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 182.884277929\n",
      "Time cost: 4.34257602692 seconds\n"
     ]
    }
   ],
   "source": [
    "# forecasting using test data\n",
    "start_time = time()\n",
    "pred_prices = list()\n",
    "actual_prices = test_data[option].tolist()[1:]\n",
    "indices = test_data.index\n",
    "d1 = binary_to_decimal(SKD[0:d1_digits])\n",
    "d2 = binary_to_decimal(SKD[(d1_digits+n_digits): dim_IKD])\n",
    "n_par = binary_to_decimal(SKD[d1_digits:(d1_digits+n_digits)])\n",
    "print(\"\\t\\td1=%f, d2=%f, n=%f\" % (d1, d2, n_par))\n",
    "for i in range(len(indices)-1):\n",
    "    prev = test_data.iloc[i]\n",
    "    train_data.append(prev)\n",
    "    u_discourse = universe_partition_adjusted(train_data[option], n_par, d1, d2)\n",
    "    A_list = set_fuzzy_numbers(u_discourse)\n",
    "    train_data_membership_series = membership_assignment(train_data[option], fuzzy_numbers=u_discourse)\n",
    "    transition_FLR = FLR(train_data_membership_series)\n",
    "    train_data_days = train_data['Date'].apply(lambda x: x-first_date).dt.days.tolist() # convert Timedelta to numeric days\n",
    "    jump_weights = FLR_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    transition_weights = FRG_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    price = prev[option]\n",
    "    index = get_membership(price, u_discourse)\n",
    "    next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "    pred_prices.append(next_price)\n",
    "    \n",
    "print \"RMSE = \"+str(np.sqrt(mean_squared_error(actual_prices, pred_prices)))\n",
    "print \"Time cost: \"+str(time()-start_time)+\" seconds\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
