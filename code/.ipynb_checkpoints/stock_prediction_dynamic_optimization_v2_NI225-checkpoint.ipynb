{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with v1, but dynamically update the parameters weekly (5 trading days per week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rectangle_fuzzy import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def binary_to_decimal(binary, di=0):\n",
    "    decimal = 0\n",
    "    for i in range(len(binary)):\n",
    "        if i<len(binary)-di+1:\n",
    "            power = len(binary)-(i+1)-di\n",
    "            decimal += int(binary[i]) * (2**power)\n",
    "        else:\n",
    "            power = len(binary)-(i+1)-di\n",
    "            decimal += int(binary[i]) * (2**(-power))\n",
    "    return decimal\n",
    "\n",
    "def universe_partition_adjusted(data, n=9, d1=9, d2=10):\n",
    "    x_max, x_min = data.max(axis=0), data.min(axis=0)   \n",
    "    delta = x_max - x_min\n",
    "    std_val = data.std(axis=0)\n",
    "    len_val = np.round(std_val / (n+5)) # partition interval\n",
    "    u_max, u_min = int(x_max+(d2+1)*(delta/100)), int(x_min-(d1+1)*(delta/100)) # bound of universe discourse\n",
    "    u_b = np.arange(u_min, u_max, step=float(len_val)) # cutting points\n",
    "    u_discourse = u_b\n",
    "    return u_discourse\n",
    "\n",
    "def compute_fitness(data, n, d1, d2, option='Price'):\n",
    "    reserved_days = 5\n",
    "    first_date = data['Date'][0] - pd.DateOffset(days=1)\n",
    "    train_data = data.iloc[:-reserved_days]\n",
    "    valid_data = data.iloc[-(reserved_days+1):]\n",
    "    fit_prices = list()\n",
    "#     u_discourse = universe_partition_adjusted(train_data[option], n, d1, d2)\n",
    "    u_discourse = universe_partition_adjusted(train_data[option], n)\n",
    "    A_list = set_fuzzy_numbers(u_discourse)\n",
    "    train_data_membership_series = membership_assignment(train_data[option], fuzzy_numbers=u_discourse)\n",
    "    transition_FLR = FLR(train_data_membership_series)\n",
    "    train_data_days = train_data['Date'].apply(lambda x: x-first_date).dt.days.tolist()\n",
    "    jump_weights = FLR_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    transition_weights = FRG_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    for price in valid_data.iloc[:-1][option]:\n",
    "        index = get_membership(price, u_discourse)\n",
    "        next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "        fit_prices.append(next_price)\n",
    "    return np.sqrt(mean_squared_error(valid_data.iloc[1:][option], fit_prices))\n",
    "\n",
    "def parameter_tuning_ASHLO(data, option):\n",
    "    # initialize hyperparameters\n",
    "    d1_digits = 0\n",
    "    n_digits = 6\n",
    "    d2_digits = 0\n",
    "    population = 20\n",
    "    iter_max = 100\n",
    "    pr = 0.1\n",
    "    pi = 0.9\n",
    "    # initialize data structures\n",
    "    dim_IKD = d1_digits+n_digits+d2_digits\n",
    "    RMSE_list = list() # training data RMSE as fitness function value\n",
    "    IKD = np.zeros((population, dim_IKD), dtype=int) # individual learning \n",
    "    SKD = np.array([]) # social network learning\n",
    "    RMSE_min = 0 # best fitness value\n",
    "    for i in range(population):\n",
    "        for j in range(dim_IKD):\n",
    "            r = np.random.rand()\n",
    "            if r>0.5:\n",
    "                IKD[i, j] = 0\n",
    "            else:\n",
    "                IKD[i, j] = 1\n",
    "        d1 = binary_to_decimal(IKD[i, 0:d1_digits])\n",
    "        d2 = binary_to_decimal(IKD[i, (d1_digits+n_digits): dim_IKD])\n",
    "        n_par = binary_to_decimal(IKD[i, d1_digits:(d1_digits+n_digits)])\n",
    "        rmse = compute_fitness(data, n_par, d1, d2, option)\n",
    "        RMSE_list.append(rmse)\n",
    "    RMSE_min = np.min(RMSE_list) # best individual fitness\n",
    "    SKD = np.array(IKD[np.argmin(RMSE_list)])\n",
    "    # learning iterations\n",
    "    for iter_count in range(iter_max):\n",
    "        temp_IKD = np.zeros((population, dim_IKD))\n",
    "        temp_rmse_list = list()\n",
    "        # learning process\n",
    "        for i in range(population):\n",
    "            for j in range(dim_IKD):\n",
    "                p = np.random.rand()\n",
    "                if p < pi:\n",
    "                    r = np.random.rand()\n",
    "                    if r > 0.5:\n",
    "                        temp_IKD[i, j] = 1\n",
    "                elif pi <= p <= pr:\n",
    "                    temp_IKD[i,j] = IKD[i, j]\n",
    "                else:\n",
    "                    temp_IKD[i,j] = SKD[j]\n",
    "        # update fitness of newly learned knowledge \n",
    "        for i in range(population):\n",
    "            d1 = binary_to_decimal(temp_IKD[i, 0:d1_digits])\n",
    "            d2 = binary_to_decimal(temp_IKD[i, (d1_digits+n_digits): dim_IKD])\n",
    "            n_par = binary_to_decimal(temp_IKD[i, d1_digits:(d1_digits+n_digits)])\n",
    "            rmse = compute_fitness(data, n_par, d1, d2, option)\n",
    "            temp_rmse_list.append(rmse)\n",
    "\n",
    "        # update knowledge base if necessary\n",
    "        RMSE_max = np.max(RMSE_list) # worst individual fitness\n",
    "        RMSE_max_index = np.argmax(RMSE_list)\n",
    "        for i in range(population):\n",
    "            if temp_rmse_list[i] < RMSE_max:\n",
    "                IKD[RMSE_max_index] = temp_IKD[i]\n",
    "                RMSE_list[RMSE_max_index] = temp_rmse_list[i]\n",
    "                RMSE_max = np.max(RMSE_list)\n",
    "                RMSE_max_index = np.argmax(RMSE_list)\n",
    "        temp_rmse_min = np.min(RMSE_list) # best individual fitness\n",
    "        if RMSE_min > temp_rmse_min:\n",
    "            SKD = np.array(IKD[np.argmin(RMSE_list)])\n",
    "            RMSE_min = temp_rmse_min\n",
    "    # output optimal parameter settings        \n",
    "    d1 = binary_to_decimal(SKD[0:d1_digits])\n",
    "    d2 = binary_to_decimal(SKD[(d1_digits+n_digits): ])\n",
    "    n_par = binary_to_decimal(SKD[d1_digits:(d1_digits+n_digits)])\n",
    "    return d1, n_par, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))*100 # beware of zero division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data \n",
    "start_time = time()\n",
    "datafile = '../data/NI225.csv'\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')\n",
    "df = pd.read_csv(datafile, header=0, parse_dates=['Date'], date_parser=dateparse)\n",
    "\n",
    "split_date = pd.datetime.strptime('2014-12-31', '%Y-%m-%d')\n",
    "train_data = df[df['Date'] < split_date]\n",
    "test_data = df[df['Date'] >= split_date]\n",
    "first_date = train_data['Date'][0] - pd.DateOffset(days=1)\n",
    "\n",
    "option = 'Open'\n",
    "update_interval = 5 # days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.014296\n",
      "Iteration #1\n",
      "\t---- error percentage = 0.015839\n",
      "Iteration #2\n",
      "\t---- error percentage = 0.014857\n",
      "Iteration #3\n",
      "\t---- error percentage = 0.014103\n",
      "Iteration #4\n",
      "\t---- error percentage = 0.022108\n",
      "Iteration #5\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.000664\n",
      "Iteration #6\n",
      "\t---- error percentage = 0.005934\n",
      "Iteration #7\n",
      "\t---- error percentage = 0.005153\n",
      "Iteration #8\n",
      "\t---- error percentage = 0.010997\n",
      "Iteration #9\n",
      "\t---- error percentage = 0.005774\n",
      "Iteration #10\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.013533\n",
      "Iteration #11\n",
      "\t---- error percentage = 0.002278\n",
      "Iteration #12\n",
      "\t---- error percentage = 0.009963\n",
      "Iteration #13\n",
      "\t---- error percentage = 0.014249\n",
      "Iteration #14\n",
      "\t---- error percentage = 0.021813\n",
      "Iteration #15\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.002398\n",
      "Iteration #16\n",
      "\t---- error percentage = 0.005277\n",
      "Iteration #17\n",
      "\t---- error percentage = 0.003393\n",
      "Iteration #18\n",
      "\t---- error percentage = 0.015217\n",
      "Iteration #19\n",
      "\t---- error percentage = 0.006944\n",
      "Iteration #20\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.010205\n",
      "Iteration #21\n",
      "\t---- error percentage = 0.003252\n",
      "Iteration #22\n",
      "\t---- error percentage = 0.006922\n",
      "Iteration #23\n",
      "\t---- error percentage = 0.003481\n",
      "Iteration #24\n",
      "\t---- error percentage = 0.007972\n",
      "Iteration #25\n",
      "\tUpdate parameter setting and fuzzy sets ...\n",
      "\t\td1=0.000000, d2=0.000000, n=12.000000\n",
      "\t---- error percentage = 0.009554\n",
      "Iteration #26\n",
      "\t---- error percentage = 0.000759\n",
      "Iteration #27\n",
      "\t---- error percentage = 0.008072\n",
      "Iteration #28\n",
      "\t---- error percentage = 0.006818\n",
      "Iteration #29\n",
      "\t---- error percentage = 0.007846\n",
      "Iteration #30\n",
      "\tUpdate parameter setting and fuzzy sets ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-23659f0caf19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tUpdate parameter setting and fuzzy sets ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter_tuning_ASHLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\td1=%f, d2=%f, n=%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_par\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         u_discourse = universe_partition_adjusted(train_data[option], n_par, d1, d2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e0c3559cf854>\u001b[0m in \u001b[0;36mparameter_tuning_ASHLO\u001b[0;34m(data, option)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_to_decimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_IKD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md1_digits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdim_IKD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mn_par\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_to_decimal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_IKD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1_digits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1_digits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mtemp_rmse_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e0c3559cf854>\u001b[0m in \u001b[0;36mcompute_fitness\u001b[0;34m(data, n, d1, d2, option)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_data_membership_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmembership_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuzzy_numbers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_discourse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtransition_FLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_membership_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrain_data_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfirst_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mjump_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLR_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_FLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_days\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_FLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtransition_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFRG_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_FLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_days\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_FLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m_getter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delegate_property_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_setter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/tseries/common.pyc\u001b[0m in \u001b[0;36m_delegate_property_get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# maybe need to upcast (ints)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/tseries/tdi.pyc\u001b[0m in \u001b[0;36mdays\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;34m\"\"\" Number of days for each element. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'days'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/tseries/tdi.pyc\u001b[0m in \u001b[0;36m_get_field\u001b[0;34m(self, m)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             result = np.array([getattr(Timedelta(val), m)\n\u001b[0;32m--> 382\u001b[0;31m                                for val in values], dtype='int64')\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# forecasting using test data\n",
    "start_time = time()\n",
    "pred_prices = list()\n",
    "error_percentages = list() # percentage of forecasting residual\n",
    "actual_prices = test_data[option].tolist()[1:]\n",
    "indices = test_data.index\n",
    "for i in range(len(indices)-1):\n",
    "    print(\"Iteration #%s\" % str(i))\n",
    "    prev = test_data.iloc[i]\n",
    "    train_data.append(prev)\n",
    "    if (i % update_interval)==0:\n",
    "        print(\"\\tUpdate parameter setting and fuzzy sets ...\")\n",
    "        d1, n_par, d2 = parameter_tuning_ASHLO(train_data, option)\n",
    "        print(\"\\t\\td1=%f, d2=%f, n=%f\" % (d1, d2, n_par))\n",
    "#         u_discourse = universe_partition_adjusted(train_data[option], n_par, d1, d2)\n",
    "        u_discourse = universe_partition_adjusted(train_data[option], n_par)\n",
    "        A_list = set_fuzzy_numbers(u_discourse)\n",
    "        train_data_membership_series = membership_assignment(train_data[option], fuzzy_numbers=u_discourse)\n",
    "        transition_FLR = FLR(train_data_membership_series)\n",
    "        train_data_days = train_data['Date'].apply(lambda x: x-first_date).dt.days.tolist() # convert Timedelta to numeric days\n",
    "        jump_weights = FLR_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "        transition_weights = FRG_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "    price = prev[option]\n",
    "    index = get_membership(price, u_discourse)\n",
    "    next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "    pred_prices.append(next_price)\n",
    "    pred_ep = (np.abs(actual_prices[i] - next_price)/actual_prices[i])\n",
    "    error_percentages.append(pred_ep)\n",
    "    print(\"\\t---- error percentage = %f\" % pred_ep)\n",
    "    \n",
    "print \"MAD = \"+str(mean_absolute_error(actual_prices, pred_prices))\n",
    "print \"RMSE = \"+str(np.sqrt(mean_squared_error(actual_prices, pred_prices)))\n",
    "print \"MAPE = \"+str(mean_absolute_percentage_error(actual_prices, pred_prices))\n",
    "print \"Time cost: \"+str(time()-start_time)+\" seconds\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_data.iloc[1:]['Date'])\n",
    "df_test['data testing'] = pd.Series(actual_prices).values\n",
    "df_test['forecasting'] = pd.Series(pred_prices).values\n",
    "df_test.index = df_test['Date']\n",
    "plt.figure(figsize=(14,7))\n",
    "df_test['data testing'].plot(style='k-', linewidth=2, label='data testing')\n",
    "df_test['forecasting'].plot(style='g:', linewidth=3, label='forecasting')\n",
    "plt.ylabel('Price', fontsize=18)\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"NI225_forecasting\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "df_test[\"residual\"] = df_test[\"data testing\"] - df_test[\"forecasting\"]\n",
    "df_test[\"residual\"].plot(style='bo', linewidth=3, label='residual')\n",
    "plt.ylabel('Residual', fontsize=18)\n",
    "plt.axhline(y=0.0, color='k', linestyle='--')\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"NI225_forecasting_residual\", fontsize=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
