{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: extend discourse and fuzzy number coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "py.sign_in('imaginationsuper', 'PQj7gXzsTJFqNKsXkWMT')\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def universe_partition(data, d1=10, d2=10):\n",
    "    x_max, x_min = data.max(axis=0), data.min(axis=0)\n",
    "    std_val = data.std(axis=0)\n",
    "    len_val = np.round(std_val / 10)\n",
    "#     len_val = 30\n",
    "    u_max, u_min = int(x_max+d2), int(x_min-d1) # bound of universe discourse\n",
    "    u_b = np.arange(u_min, u_max, step=float(len_val)) # cutting points\n",
    "    u_s = u_b[:-1] # u1\n",
    "    u_e = u_b[1:] # u2\n",
    "    u_discourse = zip(u_b, u_e) # interval\n",
    "    return u_discourse\n",
    "\n",
    "def set_fuzzy_numbers(u_discourse):\n",
    "    fuzzy_numbers = list()\n",
    "    for i, u_i in enumerate(u_discourse):\n",
    "        if (i!=0) and (i!=len(u_discourse)-1):\n",
    "            u_l, u_r = u_discourse[i-1], u_discourse[i+1]\n",
    "            A_l, A_r = np.mean(u_l), np.mean(u_r)\n",
    "            fuzzy_numbers.append((A_l, u_i[0], u_i[1], A_r))\n",
    "    return fuzzy_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def membership_evaluation(value, fuzzy_number):\n",
    "    A_l, u_1, u_2, A_r = fuzzy_number\n",
    "    mu = 0 # membership indication\n",
    "    try:\n",
    "        if np.logical_and(value>=A_l, value <u_1):\n",
    "            mu = (value - A_l) / (u_1 - A_l)\n",
    "        elif np.logical_and(value>=u_1, value<=u_2):\n",
    "            mu = 1\n",
    "        elif np.logical_and(value>u_2, value<=A_r):\n",
    "            mu = (value - u_2) / (A_r - u_2)\n",
    "    except ZeroDivisionError:\n",
    "        mu = 0\n",
    "    return mu\n",
    "\n",
    "def membership_assignement(value_time_series, fuzzy_numbers):\n",
    "    n_fuzzy_numbers = len(fuzzy_numbers)\n",
    "    membership_list = list()\n",
    "    for i, value in enumerate(value_time_series):\n",
    "        value_rep = [value] * n_fuzzy_numbers\n",
    "        memberships = map(lambda val, A: membership_evaluation(val, A), value_rep, fuzzy_numbers)\n",
    "        max_index, _ = max(enumerate(memberships), key=operator.itemgetter(1))\n",
    "        membership_list.append(max_index)\n",
    "    return membership_list\n",
    "\n",
    "def get_membership(value, fuzzy_numbers):\n",
    "    n_fuzzy_numbers = len(fuzzy_numbers)\n",
    "    membership_index = 0\n",
    "    value_rep = [value] * n_fuzzy_numbers\n",
    "    memberships = map(lambda val, Ai: membership_evaluation(val, Ai), value_rep, fuzzy_numbers)\n",
    "    membership_index, _ = max(enumerate(memberships), key=operator.itemgetter(1))\n",
    "    return membership_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FLR(membership_time_series): # transition between consecutive observations\n",
    "    transitions = list()\n",
    "    for j, Aj in enumerate(membership_time_series):\n",
    "        if j!=0:\n",
    "            Ai = membership_time_series[j-1]\n",
    "            transitions.append((Ai, Aj))\n",
    "    return transitions\n",
    "\n",
    "def FLR_weight(transitions, time_series): # compute jump frequency by FLR\n",
    "    jumps = map(lambda x: x[1]-x[0], transitions) # compute jumps by transitions \n",
    "    jump_time_series = zip(jumps, time_series) # assign timestamp for each jump beta^t_p,p+k\n",
    "    jump_counts = defaultdict(list) \n",
    "    for key, value in jump_time_series:\n",
    "        jump_counts[key].append(value) # count jump by its timestamps\n",
    "    jump_counts = {key: np.sum(value) for key, value in jump_counts.items()} # sum up total time for each jump\n",
    "    total_count = float(np.sum(jump_counts.values()))\n",
    "    for key, value in jump_counts.iteritems(): \n",
    "        jump_counts[key] = value / total_count # normalize jumps as weights\n",
    "    return jump_counts\n",
    "\n",
    "def FRG_weight(transitions, time_series): \n",
    "    transition_time_series = zip(transitions, time_series)\n",
    "    transition_groups = map(lambda x: (x[0][0], (x[0][1], x[1])), transition_time_series) \n",
    "    transition_weights = defaultdict(list)\n",
    "    for key, value in transition_groups:\n",
    "        transition_weights[key].append(value) # group transitions by initial state A_i\n",
    "    transition_weights = {key: dict(value) for key, value in transition_weights.items()}\n",
    "    for key, value in transition_weights.iteritems():\n",
    "        total_weight = float(np.sum(value.values()))\n",
    "        value = {k: (v/total_weight) for k, v in value.items()} # normalize weight inside each group\n",
    "        transition_weights[key] = value\n",
    "    return transition_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forecasting by fuzzy numbers\n",
    "def fuzzy_add(A, B): # Proposition #1 (1)\n",
    "    return tuple([np.sum(x) for x in zip(A, B)])\n",
    "\n",
    "def fuzzy_scale(c, A): # Proposition #1 (2)\n",
    "    cA = [c*a for a in A]\n",
    "    if c>=0:\n",
    "        return tuple(cA)\n",
    "    else:\n",
    "        cA.reverse()\n",
    "        return tuple(cA)\n",
    "\n",
    "def forecast_jump(i, s, A_list):\n",
    "    jumps = s.keys() # possible jumps\n",
    "    m = len(A_list) # number of fuzzy numbers in model\n",
    "    sA_list = list()\n",
    "    sk_list = list()\n",
    "    Aip_list = list()\n",
    "    sA = tuple([0]*len(A_list[0]))\n",
    "    for k in jumps:\n",
    "        ip = k+i\n",
    "        if (ip>=0 and ip<m): # check if index is within range\n",
    "            sk_list.append(s[k])\n",
    "            Aip_list.append(A_list[ip])\n",
    "    sk_tot = np.sum(sk_list)\n",
    "    sk_list = [sk/float(sk_tot) for sk in sk_list] # normalize locally\n",
    "    for i in range(len(sk_list)):\n",
    "        sA_list.append(fuzzy_scale(sk_list[i], Aip_list[i]))\n",
    "    if len(sA_list)>0:\n",
    "        for sa in sA_list:\n",
    "            sA = fuzzy_add(sA, sa)\n",
    "    return sA\n",
    "    \n",
    "def forecast_transition(i, w, A_list):\n",
    "    wA = tuple([0]*len(A_list[0])) # default FLG relation\n",
    "    if i in w.keys():\n",
    "        for kj, v in w[i].iteritems():\n",
    "            wA = fuzzy_add(wA, fuzzy_scale(v, A_list[kj]))\n",
    "    return wA\n",
    "\n",
    "def forecast_price(As, Aw, gamma=0.1):\n",
    "    if gamma<0 or gamma>1:\n",
    "        raise ValueError(\"gamma should be between 0.0 and 1.0 (inclusive on both ends)\")     \n",
    "    wAi = fuzzy_scale(1-gamma, Aw)\n",
    "    if (np.sum(wAi) == 0): # no FLR observed in history\n",
    "        sAi = As\n",
    "    else:\n",
    "        sAi = fuzzy_scale(gamma, As)\n",
    "    Ai_pred = fuzzy_add(sAi, wAi)\n",
    "    return np.mean(Ai_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "# datafile = '../data/IBEX35(201301-201512).xlsx'\n",
    "# xl = pd.ExcelFile(datafile)\n",
    "# df = xl.parse(u'Sheet1')\n",
    "datafile = '../data/IBEX35.csv'\n",
    "df = pd.read_csv(datafile, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_date = '2014-12-31'\n",
    "train_data = df[df['Date'] <= split_date]\n",
    "test_data = df[df['Date'] > split_date]\n",
    "# print train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_discourse = universe_partition(train_data['Price'], d1=1053, d2=912)\n",
    "# print(u_discourse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_list = set_fuzzy_numbers(u_discourse)\n",
    "# print(A_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_membership_series = membership_assignement(train_data['Price'], fuzzy_numbers=A_list)\n",
    "train_data_ms = [ms+1 for ms in train_data_membership_series]\n",
    "# print (train_data_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_FLR = FLR(train_data_membership_series)\n",
    "# print(transition_FLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b550c936cfd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfirst_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfirst_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert Timedelta to numeric days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print train_data_days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b550c936cfd7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfirst_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfirst_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert Timedelta to numeric days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print train_data_days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "first_date = train_data['Date'][0]\n",
    "train_data_days = train_data['Date'].apply(lambda x: x-first_date).dt.days.tolist() # convert Timedelta to numeric days\n",
    "train_data_days = [d+1 for d in train_data_days]\n",
    "# print train_data_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jump_weights = FLR_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "# print (jump_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition_weights = FRG_weight(transition_FLR, train_data_days[:len(transition_FLR)])\n",
    "# print transition_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit training data\n",
    "train_features = train_data['Price'].tolist()[:-1]\n",
    "train_prices = train_data['Price'].tolist()[1:]\n",
    "fit_prices = list()\n",
    "for price in train_features:\n",
    "    index = get_membership(price, A_list)\n",
    "    next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "    fit_prices.append(next_price)\n",
    "print np.sqrt(mean_squared_error(train_prices, fit_prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forecasting test data\n",
    "test_features = [train_data['Price'].tolist()[-1]] + test_data['Price'].tolist()[:-1]\n",
    "actual_prices = test_data['Price'].tolist()\n",
    "pred_prices = list()\n",
    "for price in test_features:\n",
    "    index = get_membership(price, A_list)\n",
    "    next_price = forecast_price(forecast_jump(index, jump_weights, A_list), forecast_transition(index, transition_weights, A_list), gamma=0.9)\n",
    "    pred_prices.append(next_price)\n",
    "print \"RMSE = \"+str(np.sqrt(mean_squared_error(actual_prices, pred_prices)))\n",
    "print \"Time cost: \"+str(time()-start_time)+\" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_data[1:]['Date'])\n",
    "df_train['data training'] = pd.Series(train_prices).values\n",
    "df_train['data fitting'] = pd.Series(fit_prices).values\n",
    "df_train.index = df_train['Date']\n",
    "plt.figure(figsize=(14,7))\n",
    "df_train['data training'].plot(style='k-', linewidth=2, label='data training')\n",
    "df_train['data fitting'].plot(style='b:', linewidth=3, label='data fitting')\n",
    "plt.ylabel('Price', fontsize=18)\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"IBEX35_fitting\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_data['Date'])\n",
    "df_test['data testing'] = pd.Series(actual_prices).values\n",
    "df_test['forecasting'] = pd.Series(pred_prices).values\n",
    "df_test.index = df_test['Date']\n",
    "plt.figure(figsize=(14,7))\n",
    "df_test['data testing'].plot(style='k-', linewidth=2, label='data testing')\n",
    "df_test['forecasting'].plot(style='g:', linewidth=3, label='forecasting')\n",
    "plt.ylabel('Price', fontsize=18)\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"IBEX35_forecasting\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
